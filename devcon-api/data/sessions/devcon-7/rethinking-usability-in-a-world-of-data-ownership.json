{
  "id": "rethinking-usability-in-a-world-of-data-ownership",
  "sourceId": "RKNJED",
  "title": "Rethinking usability in a world of data ownership",
  "description": "What makes something usable in a world where the internet is built on open source cryptography? This talk explores how we might consider choice a key factor in the usability of applications where we are owners of our data which we can port, wield, and disclose at our discretion with other data owners. I will illustrate how we are testing our hypothesis that cryptography can surface meaningful connections through demo applications that embrace choice as a key usability factor.",
  "track": "Usability",
  "type": "Talk",
  "expertise": "Beginner",
  "audience": "",
  "featured": false,
  "doNotRecord": false,
  "tags": [
    "data",
    "ownership",
    "Best Practices",
    "Design Thinking",
    "MPC"
  ],
  "keywords": [
    "applications",
    "social graphs",
    "data ownership"
  ],
  "duration": 1390,
  "language": "en",
  "sources_swarmHash": "",
  "sources_youtubeId": "",
  "sources_ipfsHash": "",
  "sources_livepeerId": "",
  "sources_streamethId": "673424cc9dbb7a90e18ec653",
  "transcript_vtt": "https://streameth-develop.ams3.digitaloceanspaces.com/transcriptions/673424cc9dbb7a90e18ec653.vtt",
  "transcript_text": " Tanya Cushman Reviewer Reviewer Alright. Hey everyone. I want to start with a little poll of the room. So, can you raise your hand if you ever opened a social app to connect with a friend, that was your intention, only to get lost in some content that you can't look away from? Okay, yes. So relatable experience. Maybe even this week, while you were in Chiang Mai, you meant to check in with a friend, send them... Or sorry, we're in Bangkok now. You meant to check in with friends, send them photos of your trip, but you got busy. Catching up on important content. And maybe you're thinking, yeah, Rachel, that's ads-based social media. It's for dopamine hits. And you're not wrong. But here's the thing. These platforms were built on a promise of bringing people together. Many still claim human connection as their core mission. So today I want to examine this disconnect. For those of us genuinely seeking meaningful relationships through these social apps, are they actually helping us achieve that? And more importantly, how does our lack of data ownership undermine our ability to truly connect? Let me take you back a little bit. Before I was a designer, I had my fair share of rage over government websites and healthcare portals that made it really hard to be an informed, law-abiding citizen. And when I learned about the field of UX, I was giddy over this idea that services could actually be improved to the point of making it easier for people to do hard tasks. I couldn't wait to start honing this craft. And when going into the field, I think a lot of us are introduced to this book that gets recommended as essential reading called Don't Make Me Think. It's filled with a lot of amazing principles for removing friction for users so that they can achieve their goals. And while many public service applications, at least in the States, are still decades behind by usability standards. Social media apps have nailed these principles. They're so easy that you're served exactly what you like before you even have to think about what you want from the app. But my question is when does easy become too easy? When do thoughtfully crafted UX principles cross the line from enabling to exploitative? What happens when frictionless design and our surrendered data serve profit rather than people? When social apps make us feel good for at least some of the time, we often end up entrusting a lot of our personal data to these centralized systems. But that convenience to entrust others to custody, manage, and use our data introduces some additional vulnerabilities. The cost can come in different forms, like losing sentimental things we thought were permanently ours. Or potential genuine connections with other humans lost. If our accounts get hacked or we get banned for maybe unjust reasons. So, yeah. Imagine losing all of these things. But perhaps most relevant right now is what if we lose genuine quality time with the people that we care about to successful attention capture? And as a DevCon attendee, this might be old news for some of you, but for the average consumer it may not be obvious that the companies will use our behavioral and informational data to bait us into opening their app and keeping it open longer to maximize the number of eyeballs on ads. And I believe all of these costs are making us feel less connected to the people we actually want to connect to. I think it's really important to remember that designing for usability isn't as simple as ease of use. It's about designing systems that help users actually achieve their goals. There was this time when I believed these popular social apps could be a place to connect, and it always felt strange that these connections happened publicly by writing on each other's walls, or that all of my interests were broadcast to all of my friends. I remember exactly when it clicked for me that the promise of connection here was an empty one. So when this ad ran in 2022 that claimed personalized ads make for a better world by helping us fit in and be happier by buying more products. The tagline was, good ideas deserve to be found. For this brief moment, there was full embrace of the truth. The video has since been deleted from YouTube. So, I don't know. Maybe they realized they couldn't convince users that buying things would make them feel less empty inside. And while we see now the return to human connection rhetoric externally. You'll find a focus on content consumption if you look a little deeper. I thought I would find empowering users in a lot of designers' bios with a quick search, but the focus seems to be primarily on empowering creators, creators of content. The goal is getting more people creating more content that keeps folks on the apps longer. The user desire for a genuine human connection remains unmet. So what happens when we flip the script? When we put data back in users' hands, genuine connection becomes more than just website copy. Let's examine this through the three pillars of usability. Effectiveness, efficiency, and safety. And I want you to like do some thought exercises with me. What might it feel like to use a more effective social app that helps us go back to achieving that goal of connecting with other people. Maybe we reconsider the don't-make-me-think philosophy. Instead of algorithmic suggestions that keep us scrolling past our bedtimes, imagine apps that aren't trying to hijack our attention. Imagine no more For You page bombarding you with content the moment you open the app to message a friend. Instead, you see tools for intentional connection. You, not an algorithm, decide what connections would be meaningful. You choose what to share, when to share it, and who sees it by utilizing your private, portable social graph. Now let's consider efficiency. When we own our data, could we more efficiently connect with other users? Instead of broadcasting information, perhaps we would narrowcast it. What if instead of putting your life on display by posting and liking on public pages, you could intentionally connect with specific people by only revealing your private data to those who meet certain match criteria. Almost like putting digital pheromones out into the ether. You might do this to find friends who share your interests, connect with mentors who complement your skills, discover people in your community with similar or differing perspectives, or discreetly signal that you're open to new work opportunities only if they meet certain requirements. Lastly, how might safety be enhanced when users own their data? I like to think about these three varieties of safety for users. There's technical, social, and psychological. From a technical standpoint, safety can increase for users when builders commit to using open source code for encrypting user data. Instead of saying trust us, they Imagine being able to control what you share with who. Go back to that. And the feeling of social safety that that might bring if we had even more control over this process than we currently do. And now put yourself in the future when these applications have been refined through many iterations by awesome builders that are in this community. Lots of user testing has been done. And you have full control over defining the experiences you want to have utilizing your data. Imagine the psychological safety that might bring if the expectations remain consistent and remain consistently met. This isn't just theoretical. It's UX principles in practice. Instead of optimizing for purely engagement metrics, we're optimizing for actual human connection. When we own our data, we're free to connect on our own terms, not through the lens of what's most profitable for the platform. So now picture yourself opening a social app and actually connecting with a friend instead of getting lost in a feed designed to keep you scrolling. To me, that's the promise of user-owned data, where technology enhances our relationships instead of competing with them. At Cursive, we're experimenting with these ideas, you can get an NFC chip at our booth on the first floor to start building your own private portable social graph to make MPC queries over. So you can try out some of these examples that I gave in the presentation, where you add your things that you're interested in, ways that you want to connect with people, and while our servers don't see the data you're adding, we're running this cool cryptography that if you do have a match over private data with another person on the app, you'll be notified and connected. There's a lot of design challenges in this space. I think they're really fun to think through and I am excited to meet people who are excited to talk through these challenges. I would love to invite all of you to join us in redefining usability for an era of data ownership because I believe authentic connection is worth designing for. Our work is funded by Privacy and Scaling Explorations who I've been with for the past three years. We have an impact booth right out here in the hallway so you can check out more of this open source tooling that makes app experiences like the cursive one possible. Thank you so much. Thank you for a super interesting talk. Yeah. I think we have a few questions from the audience. The first one, besides cursive, can you give classic or future use cases or examples? What are current projects that meet the UX and decentralized ownership? That's something, honestly, that I want to learn more about. So if you have ideas, please share them with me because doing more comparative research and testing these tools is a really important part of all of us improving. The next question, ads are a way of supporting and paying for services. How should builders and designers balance business needs with usability? Yeah, this is a great question. And I think we're in this privileged position that I think is so valuable that this work is funded in the way that it is so that we can run these experiments. And I think that there is some learning that we can run these experiments. And like, I think that there is some learning to be had, and the discovery to the answer to that question will come through trial and error and testing. I think a lot of these ideas felt like pipe dreams a year ago. Like, oh, it would be crazy if we could do this, if we could actually put this into production. And the only reason that everyone here can even try the app that is in production now is from so many cycles of testing these advanced cryptography in production. So yeah, I don't know if I have the answer to that question at this time, but I think that this builder and experiment phase is really important. There's some related questions, but this one's a bit different. Can you talk about the underlying consent models baked into cursive? I really want to encourage everyone who's interested in more of the technical aspects of this. Like, you know, I'm really brushing the surface to go to Vivek's talk at 3.30 today because he's going to be talking, he's going to be getting into how we achieve what is going on in the app that you can experience. Ads are a way of supporting and paying for services. How should builders and designers balance business needs with usability? So, okay, this is something I'm excited to explore. If you want to talk about it, come find me, because I want to try and understand this better. But when I was kind of looking at my maps of things for this talk, it's like we have in the classic models with ads, users, the application company, and then advertisers. So like you're optimizing for that relationship between the advertisers and the business. But like what if, I don't know, you can remove that party? Are there, uh, I wanted to check the question, but it's gone. Are there ways, like, to try and balance those things? I mean, I think that, like, you know, less, like, paid services is one route to explore. Another question. Right now, users already have the option to control whom their data is shared with on Facebook. People don't bother to go into those settings and change them. How will this be different with Web3? I think that there is this feeling of like nobody cares. No one cares about privacy. But as time goes on, I see more and more people in my life like caring, but it's not until they actually experience the consequences that I kind of like, you know, dug into a little bit in this presentation to give like some personal examples that have made my friends stop and think about how they're managing their privacy and they're thinking about conceptualizing data ownership. One of my friends got her Facebook hacked and she lost all of her photos. Like that was where every photo from like our middle school, high school, college was stored. And like feeling that collective loss of all of these memories in a friend group, I don't know, hit everyone as like, this isn't ours. This isn't this person's. So I think it will, I think we'll see it change over time and people wanting more optionality. We have, I think we have time for one more question. Love the talk. Have you considered that without the attention economy, social apps might not be sticky enough to onboard enough people to actually feel useful? Yeah, I definitely think that this is a valid concern. And I think, you know, I'm interested in exploring, like, what is useful? What utility could we bring to people. One thing that's been on my mind is maybe it's not about maximizing the time you're on the app and making your connections in it maybe it's just about like the starting point of realizing oh there's someone in this room that I could have like a really cool conversation with if I just have some amount of awareness that we're both here so I'm like trying to conceptualize this different relationship with the applications we're using, where it's not like so much I'm in my hotel room and I'm sending messages to catch up. It's more like in the moment, how can it change the experience I'm having in a community, in a space, in a group? I think we're running out of time for questions, but if anybody else has a question, they can go to the cursive booth, and I think Rachel will be there to answer them later today. Yeah, and lots of other amazing teammates who are helping build this experience.",
  "eventId": "devcon-7",
  "slot_start": 1731468600000,
  "slot_end": 1731470400000,
  "slot_roomId": "stage-6",
  "resources_presentation": "https://docs.google.com/presentation/d/1J2Pvcrn11ngEmYIecAN4U40wGXlrktRwNsT9I3TM-YM",
  "resources_slides": null,
  "speakers": [
    "rachel"
  ]
}