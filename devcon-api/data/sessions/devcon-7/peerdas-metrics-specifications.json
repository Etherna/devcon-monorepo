{
  "id": "peerdas-metrics-specifications",
  "sourceId": "UYPWVK",
  "title": "PeerDAS metrics specifications",
  "description": "The PeerDAS Metrics Specifications help make testing more efficient and straightforward by creating standard metrics for Consensus clients. With a unified Grafana dashboard, teams can monitor performance in real-time, compare client data side by side, and quickly spot issues. This approach makes troubleshooting faster, supports research, and encourages teamwork, helping strengthen the Ethereum ecosystem and improve scalability.",
  "track": "[CLS] EPF Day",
  "type": "Lightning Talk",
  "expertise": "Intermediate",
  "audience": "Engineering",
  "featured": false,
  "doNotRecord": false,
  "tags": [
    "Core Protocol",
    "Testing",
    "Tooling"
  ],
  "keywords": [
    "DevOps"
  ],
  "duration": 706,
  "language": "en",
  "sources_swarmHash": "",
  "sources_youtubeId": "",
  "sources_ipfsHash": "",
  "sources_livepeerId": "",
  "sources_streamethId": "67347b4e9dbb7a90e15bbdc6",
  "transcript_vtt": "https://streameth-develop.ams3.digitaloceanspaces.com/transcriptions/67347b4e9dbb7a90e15bbdc6.vtt",
  "transcript_text": " All right. Hi, everyone. My name is Katya Ryzantseva, and my project is peer So, I'm not going to dive into what S-peer does, it's been mentioned already, so it's scaling solution for data availability. And all of you know that Ethereum protocols built with according to the consensus and execution specs. But the metrics for different clients are different. I mean, we don't have the unified metrics for the clients. It's challenging for core devs to compare the different clients and for the DevOps team it's challenging to monitor all the clients, there are a lot of them, and it's also difficult for research to get the unified data to synchronize the data. So the solution is one dashboard for all clients. And the unified metrics specs. So how it worked before? We had different dashboards for every client, different graphs, so to compare different clients it was quite painful. What do we have now for peer DAS? We have a single dashboard with different clients. The metrics implemented for Grandin, for Lighthouse, for Teco, and Grandin, Lighthouse, TecoO and, uh, Grundy in lighthouse, tackle and prison a little bit. So, uh, for this dashboard you can apply filters. Um, you can choose if it's a full note or super note. Um, you can choose one client, two clients, all clients, and you can also choose an instance and compare or monitor or wherever you need. Let's look at some examples. This blue client implemented some feature. This one is peer-dust and the field.",
  "eventId": "devcon-7",
  "slot_start": 1731483900000,
  "slot_end": 1731484800000,
  "slot_roomId": "breakout-1",
  "resources_presentation": "https://docs.google.com/presentation/d/1K_w0rS7tGijHA1ThVt6Mzpg7shFMcaOpglVD01dIMPQ",
  "resources_slides": null,
  "speakers": [
    "ekaterina-riazantseva"
  ]
}